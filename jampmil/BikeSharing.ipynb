{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Creating Training & Testing Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_train = pd.read_csv('../train.csv',header = 0)\n",
    "original_test = pd.read_csv('../test.csv',header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = original_train.copy()\n",
    "df_train['month'] = pd.DatetimeIndex(df_train.datetime).month\n",
    "df_train['day'] = pd.DatetimeIndex(df_train.datetime).dayofweek\n",
    "df_train['hour'] = pd.DatetimeIndex(df_train.datetime).hour\n",
    "df_train = df_train.drop(['datetime','casual','registered'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_y = df_train['count'].values\n",
    "df_train_x = df_train.drop(['count'],axis = 1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = original_test.copy()\n",
    "df_test['month'] = pd.DatetimeIndex(df_test.datetime).month\n",
    "df_test['day'] = pd.DatetimeIndex(df_test.datetime).dayofweek\n",
    "df_test['hour'] = pd.DatetimeIndex(df_test.datetime).hour\n",
    "df_test = df_test.drop(['datetime'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Data View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  holiday  workingday  weather  temp   atemp  humidity  windspeed  \\\n",
       "0       1        0           0        1  9.84  14.395        81        0.0   \n",
       "1       1        0           0        1  9.02  13.635        80        0.0   \n",
       "\n",
       "   count  month  day  hour  \n",
       "0     16      1    5     0  \n",
       "1     40      1    5     1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season          int64\n",
       "holiday         int64\n",
       "workingday      int64\n",
       "weather         int64\n",
       "temp          float64\n",
       "atemp         float64\n",
       "humidity        int64\n",
       "windspeed     float64\n",
       "count           int64\n",
       "month           int32\n",
       "day             int32\n",
       "hour            int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10886, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross Validation Generator\n",
    "cv = cross_validation.ShuffleSplit(len(df_train_x), n_iter=3, test_size=0.2,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function that prints the prediction according the submission format\n",
    "def printPrediction(pred, fileName='pred.csv'):\n",
    "    str_prediction = \"datetime,count\\n\"\n",
    "    for i in range(0, len(pred)):\n",
    "        datetime = original_test['datetime'][i]\n",
    "        currentPred = int(round(pred[i]))\n",
    "        str_prediction += \"{},{}\\n\".format(datetime, currentPred)\n",
    "\n",
    "    #print str_prediction\n",
    "    f = open(fileName,'w')\n",
    "    f.write(str_prediction)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print \"SVR(kernel='rbf',C=10,gamma=.001)\"\n",
    "for train, test in cv:\n",
    "    \n",
    "    svc = svm.SVR(kernel ='rbf', C = 10, gamma = .001).fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))\n",
    "\n",
    "print \"Ridge\"    \n",
    "for train, test in cv:    \n",
    "    svc = linear_model.Ridge().fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))\n",
    "    \n",
    "print \"Random Forest(n_estimators = 100)\"    \n",
    "for train, test in cv:    \n",
    "    svc = RandomForestRegressor(n_estimators = 100).fit(df_train_data[train], df_train_target[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        svc.score(df_train_data[train], df_train_target[train]), svc.score(df_train_data[test], df_train_target[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2\n",
      "Best parameters set found on development set:\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "           max_leaf_nodes=None, min_samples_leaf=10, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "           splitter='best')\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.795 (+/-0.007) for {'max_depth': 9}\n",
      "0.795 (+/-0.006) for {'max_depth': 10}\n",
      "0.787 (+/-0.009) for {'max_depth': 11}\n",
      "0.740 (+/-0.008) for {'max_depth': 20}\n",
      "0.738 (+/-0.009) for {'max_depth': 25}\n",
      "0.740 (+/-0.007) for {'max_depth': 50}\n",
      "0.741 (+/-0.010) for {'min_samples_leaf': 1}\n",
      "0.761 (+/-0.007) for {'min_samples_leaf': 2}\n",
      "0.797 (+/-0.006) for {'min_samples_leaf': 5}\n",
      "0.806 (+/-0.006) for {'min_samples_leaf': 10}\n",
      "0.758 (+/-0.010) for {'min_samples_leaf': 50}\n",
      "0.702 (+/-0.007) for {'min_samples_leaf': 100}\n",
      "0.741 (+/-0.008) for {'min_samples_split': 1}\n",
      "0.738 (+/-0.009) for {'min_samples_split': 2}\n",
      "0.753 (+/-0.008) for {'min_samples_split': 5}\n",
      "0.778 (+/-0.009) for {'min_samples_split': 10}\n",
      "0.799 (+/-0.006) for {'min_samples_split': 50}\n",
      "0.779 (+/-0.007) for {'min_samples_split': 100}\n",
      "0.742 (+/-0.008) for {'presort': True}\n",
      "0.739 (+/-0.010) for {'presort': False}\n",
      "0.736 (+/-0.010) for {'min_weight_fraction_leaf': 0.0}\n",
      "0.739 (+/-0.009) for {'min_weight_fraction_leaf': 0.1}\n",
      "0.740 (+/-0.008) for {'min_weight_fraction_leaf': 0.3}\n",
      "0.742 (+/-0.011) for {'min_weight_fraction_leaf': 0.4}\n",
      "0.746 (+/-0.008) for {'min_weight_fraction_leaf': 0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finding best parameters\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    df_train_x, df_train_y, test_size=0.3, random_state=0)\n",
    "\n",
    "tuned_parameters = [\n",
    "    {'max_depth':[9,10,11,20,25,50]},\n",
    "    {'min_samples_leaf':[1,2,5,10,50,100]},\n",
    "    {'min_samples_split':[1,2,5,10,50,100]},\n",
    "    {'presort':[True, False]},\n",
    "    {'min_weight_fraction_leaf':[0.0, 0.1, 0.3, 0.4, 0.5]}]   \n",
    "    \n",
    "scores = ['r2']\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print score\n",
    "    \n",
    "    clf = GridSearchCV(tree.DecisionTreeRegressor(), tuned_parameters, cv=5, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    \n",
    "    #best_estimator_ returns the best estimator chosen by the search\n",
    "    print(clf.best_estimator_)\n",
    "    print \"\"\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print \"\"\n",
    "    #grid_scores_ returns:\n",
    "    #    * a dict of parameter settings\n",
    "    #    * the mean score over the cross-validation folds \n",
    "    #    * the list of scores for each fold\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.882, test score: 0.804\n",
      "\n",
      "train score: 0.881, test score: 0.832\n",
      "\n",
      "train score: 0.881, test score: 0.818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "dtr = tree.DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
    "           max_leaf_nodes=None, min_samples_leaf=10, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "           splitter='best')\n",
    "for train, test in cv:\n",
    "    clf = dtr.fit(df_train_x[train], df_train_y[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        clf.score(df_train_x[train], df_train_y[train]), clf.score(df_train_x[test], df_train_y[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predicting & Exporting File\n",
    "dtr_pred = dtr.predict(df_test)\n",
    "printPrediction(dtr_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2\n",
      "Best parameters set found on development set:\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
      "           min_samples_split=1, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.847 (+/-0.003) for {'max_depth': 50}\n",
      "0.847 (+/-0.004) for {'max_depth': 100}\n",
      "0.847 (+/-0.003) for {'max_depth': 500}\n",
      "0.848 (+/-0.002) for {'max_depth': 1000}\n",
      "0.843 (+/-0.004) for {'min_samples_leaf': 1}\n",
      "0.845 (+/-0.003) for {'min_samples_leaf': 2}\n",
      "0.844 (+/-0.004) for {'min_samples_leaf': 5}\n",
      "0.837 (+/-0.005) for {'min_samples_leaf': 10}\n",
      "0.771 (+/-0.004) for {'min_samples_leaf': 50}\n",
      "0.693 (+/-0.007) for {'min_samples_leaf': 100}\n",
      "0.849 (+/-0.003) for {'min_samples_split': 1}\n",
      "0.846 (+/-0.005) for {'min_samples_split': 2}\n",
      "0.843 (+/-0.004) for {'min_samples_split': 5}\n",
      "0.848 (+/-0.005) for {'min_samples_split': 10}\n",
      "0.826 (+/-0.005) for {'min_samples_split': 50}\n",
      "0.793 (+/-0.006) for {'min_samples_split': 100}\n",
      "0.845 (+/-0.004) for {'min_weight_fraction_leaf': 0.0}\n",
      "0.517 (+/-0.008) for {'min_weight_fraction_leaf': 0.1}\n",
      "0.377 (+/-0.006) for {'min_weight_fraction_leaf': 0.3}\n",
      "0.172 (+/-0.010) for {'min_weight_fraction_leaf': 0.4}\n",
      "0.001 (+/-0.001) for {'min_weight_fraction_leaf': 0.5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Finding best parameters\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    df_train_x, df_train_y, test_size=0.3, random_state=0)\n",
    "\n",
    "tuned_parameters = [\n",
    "    {'max_depth':[50,100, 500, 1000]}, #Best: 1000\n",
    "    #{'n_estimators':[1000, 10000]}, #We assume is 1000\n",
    "    {'min_samples_leaf':[1,2,5,10,50,100]}, #2\n",
    "    {'min_samples_split':[1,2,5,10,50,100]}, #10\n",
    "    {'min_weight_fraction_leaf':[0.0, 0.1, 0.3, 0.4, 0.5]}] #0.0    \n",
    "    \n",
    "scores = ['r2']\n",
    "\n",
    "for score in scores:\n",
    "    \n",
    "    print score\n",
    "    \n",
    "    clf = GridSearchCV(RandomForestRegressor(), tuned_parameters, cv=5, scoring=score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    \n",
    "    #best_estimator_ returns the best estimator chosen by the search\n",
    "    print(clf.best_estimator_)\n",
    "    print \"\"\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print \"\"\n",
    "    #grid_scores_ returns:\n",
    "    #    * a dict of parameter settings\n",
    "    #    * the mean score over the cross-validation folds \n",
    "    #    * the list of scores for each fold\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() / 2, params))\n",
    "    print \"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.941, test score: 0.860\n",
      "\n",
      "train score: 0.940, test score: 0.876\n",
      "\n",
      "train score: 0.941, test score: 0.866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "rfr = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=1000,\n",
    "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=2,\n",
    "           min_samples_split=10, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=1000, n_jobs=1, oob_score=False, random_state=None,\n",
    "           verbose=0, warm_start=False)\n",
    "    \n",
    "for train, test in cv:\n",
    "    clf = rfr.fit(df_train_x[train], df_train_y[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "        clf.score(df_train_x[train], df_train_y[train]), clf.score(df_train_x[test], df_train_y[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predicting & Exporting File\n",
    "rfr_pred = rfr.predict(df_test)\n",
    "printPrediction(rfr_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.982, test score: 0.871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TRAINING WITH BEST PARAMETERS FOUND\n",
    "rfr = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
    "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
    "           verbose=0, warm_start=False)\n",
    "\n",
    "svc2 = rfr.fit(df_train_data[train], df_train_target[train])\n",
    "print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(\n",
    "    svc2.score(df_train_data[train], df_train_target[train]), svc2.score(df_train_data[test], df_train_target[test])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#PREDICT TEST DATA\n",
    "df_test_to_pred = df_test.drop(['datetime', 'year'], axis = 1)\n",
    "test_pred = rfr.predict(df_test_to_pred)\n",
    "\n",
    "str_prediction = \"datetime,count\\n\"\n",
    "for i in range(0, len(test_pred)):\n",
    "    datetime = df_test['datetime'][i]\n",
    "\n",
    "    pred = int(round(test_pred[i]))\n",
    "    str_prediction += \"{},{}\\n\".format(datetime, pred)\n",
    "\n",
    "#print str_prediction\n",
    "f = open('pred.csv','w')\n",
    "f.write(str_prediction)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
